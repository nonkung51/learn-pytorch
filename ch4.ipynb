{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.7.4-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python37464bitanaconda3conda1a822e7a2dad4e8482fcc886b374f68c",
   "display_name": "Python 3.7.4 64-bit ('anaconda3': conda)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "Net(\n  (fc1): Linear(in_features=784, out_features=64, bias=True)\n  (fc2): Linear(in_features=64, out_features=64, bias=True)\n  (fc3): Linear(in_features=64, out_features=64, bias=True)\n  (fc4): Linear(in_features=64, out_features=10, bias=True)\n)\n"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor(0.3594, grad_fn=<NllLossBackward>)\ntensor(0.0019, grad_fn=<NllLossBackward>)\ntensor(0.0814, grad_fn=<NllLossBackward>)\n"
    }
   ],
   "source": [
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "e+01,\n         -1.7630e+01, -3.1933e+01, -6.1391e-05, -1.6466e+01, -1.3667e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.4036e+01, -1.7979e+01, -1.8353e+01, -1.4367e+01, -2.2451e+01,\n         -2.0490e-04, -8.5256e+00, -2.3622e+01, -1.2173e+01, -1.7224e+01],\n        [-2.1168e+01, -1.6208e+01, -1.8454e+01, -2.3879e+01, -2.9802e-06,\n         -1.8725e+01, -1.9299e+01, -1.7252e+01, -1.9536e+01, -1.2747e+01],\n        [-2.7187e+01, -1.3576e+01, -1.5697e+01, -3.1113e-05, -2.6811e+01,\n         -1.0458e+01, -3.3937e+01, -1.8501e+01, -1.3884e+01, -1.6565e+01],\n        [-1.5679e+01, -1.7143e+01, -1.3480e+01, -2.0690e+01, -5.0068e-06,\n         -1.6421e+01, -1.4624e+01, -1.4890e+01, -1.7577e+01, -1.2944e+01],\n        [-8.7788e+00, -4.7955e+00, -2.2674e-01, -5.2931e+00, -1.6250e+01,\n         -7.8849e+00, -1.1858e+01, -6.5141e+00, -1.6737e+00, -1.1007e+01],\n        [-1.1764e+01, -9.7106e+00, -1.0759e+01, -7.6667e+00, -1.1508e+01,\n         -7.2733e+00, -8.9162e+00, -1.3776e+01, -2.8342e-03, -6.5478e+00],\n        [-2.3575e+01, -7.1526e-07, -2.1111e+01, -2.3133e+01, -1.4563e+01,\n         -2.0608e+01, -2.0146e+01, -1.5737e+01, -1.6036e+01, -1.8325e+01],\n        [-2.4091e+01, -1.7874e+01, -2.1497e+01, -1.2971e+01, -2.4306e+01,\n         -2.6226e-06, -1.8790e+01, -1.9827e+01, -1.5188e+01, -1.7036e+01],\n        [-2.0325e+01, -7.8678e-06, -1.7530e+01, -1.9128e+01, -1.2554e+01,\n         -1.6738e+01, -1.6769e+01, -1.2967e+01, -1.3213e+01, -1.6339e+01],\n        [-3.4250e-02, -9.1203e+00, -5.7461e+00, -7.7638e+00, -8.1742e+00,\n         -7.1271e+00, -4.5996e+00, -9.1904e+00, -4.2175e+00, -5.5309e+00]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.3555e+01, -9.5574e+00, -5.3573e-03, -9.5219e+00, -2.0803e+01,\n         -1.3212e+01, -1.5929e+01, -1.1203e+01, -5.2625e+00, -1.7772e+01],\n        [-1.9283e+01, -9.7939e+00, -1.1285e+01, -4.9324e-03, -2.1032e+01,\n         -5.3493e+00, -2.1496e+01, -1.5341e+01, -9.2173e+00, -1.3774e+01],\n        [-1.8350e+01, -1.1017e+01, -1.2331e+01, -4.3094e-03, -2.0335e+01,\n         -5.5234e+00, -2.2084e+01, -1.4340e+01, -8.2186e+00, -1.0988e+01],\n        [-2.1886e+01, -1.2510e+01, -2.1445e+01, -1.2875e+01, -2.0745e+01,\n         -9.5367e-06, -1.2722e+01, -2.2501e+01, -1.5131e+01, -1.7899e+01],\n        [-1.1795e+01, -5.8319e+00, -1.0741e+01, -1.1483e+01, -9.4668e+00,\n         -1.1349e+01, -1.8428e+01, -4.0384e-03, -1.1595e+01, -6.9487e+00],\n        [-2.9206e-05, -2.1828e+01, -1.2142e+01, -1.6625e+01, -1.7813e+01,\n         -1.4794e+01, -1.1202e+01, -1.7499e+01, -1.1825e+01, -1.2900e+01],\n        [-1.1276e+01, -1.1164e+01, -1.1619e+01, -1.3108e+01, -6.5491e+00,\n         -8.5826e+00, -2.3637e-03, -1.4806e+01, -7.2615e+00, -1.3108e+01],\n        [-1.1325e+01, -9.3456e+00, -1.1381e+01, -1.0099e+01, -1.2815e+01,\n         -7.6813e+00, -8.4929e+00, -1.4293e+01, -1.1900e-03, -7.9082e+00],\n        [-2.8820e+00, -8.2316e+00, -6.7760e+00, -6.3097e+00, -7.4622e+00,\n         -5.7492e+00, -7.8966e-02, -1.0631e+01, -4.3976e+00, -7.4388e+00],\n        [-2.0246e+01, -1.4111e+01, -1.1280e+01, -2.0407e-04, -2.2479e+01,\n         -1.1050e+01, -2.7778e+01, -1.4396e+01, -8.6678e+00, -1.3016e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-6.9427e+00, -8.5841e+00, -7.6989e+00, -8.3124e+00, -1.6092e+00,\n         -6.2818e+00, -8.4533e+00, -6.6001e+00, -5.3905e+00, -2.3559e-01],\n        [-7.3968e+00, -7.1896e+00, -7.4178e+00, -5.8717e+00, -3.0278e+00,\n         -4.3585e+00, -1.0650e+01, -2.6730e+00, -5.7966e+00, -1.4862e-01],\n        [-1.1168e+01, -7.7265e+00, -1.0463e+01, -7.7163e+00, -7.9511e+00,\n         -3.7244e+00, -4.4745e+00, -1.1636e+01, -4.0043e-02, -6.0168e+00],\n        [-8.6129e+00, -4.6591e+00, -1.7163e+00, -6.0673e+00, -1.2801e+01,\n         -6.3572e+00, -8.5699e+00, -7.6415e+00, -2.1595e-01, -9.1169e+00],\n        [-1.6033e+01, -8.5411e+00, -1.2505e+01, -1.1122e+01, -1.3344e+01,\n         -1.3580e+01, -2.5152e+01, -8.3352e-04, -1.3194e+01, -7.3946e+00],\n        [-1.9713e+01, -9.1977e+00, -1.3539e+01, -1.1684e+01, -1.4718e+01,\n         -1.5687e+01, -2.9849e+01, -2.1360e-04, -1.5215e+01, -9.1929e+00],\n        [-2.1121e+01, -7.2717e-06, -1.8183e+01, -1.9279e+01, -1.2805e+01,\n         -1.7575e+01, -1.8532e+01, -1.2580e+01, -1.3923e+01, -1.6268e+01],\n        [-4.8876e-06, -2.7085e+01, -1.3733e+01, -1.8479e+01, -1.8185e+01,\n         -1.5455e+01, -1.2737e+01, -1.6950e+01, -1.6346e+01, -1.4582e+01],\n        [-1.9967e+01, -8.5830e-06, -1.7809e+01, -2.0136e+01, -1.2359e+01,\n         -1.5669e+01, -1.3833e+01, -1.4237e+01, -1.2913e+01, -1.7754e+01],\n        [-3.0596e+01, -1.5153e+01, -2.0590e+01, -1.7445e+01, -2.2254e+01,\n         -2.5389e+01, -4.7028e+01, -5.9605e-07, -2.4967e+01, -1.4865e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.0434e+01, -8.7769e+00, -9.1215e+00, -8.9310e+00, -1.2180e+01,\n         -1.1002e+01, -1.1781e+01, -1.3119e+01, -7.7301e-04, -8.0597e+00],\n        [-1.5073e+01, -1.0617e+01, -1.7732e+01, -9.6983e+00, -3.6386e+00,\n         -1.1374e+01, -1.8652e+01, -1.0102e+01, -7.6619e+00, -2.7267e-02],\n        [-1.6593e-04, -1.8962e+01, -1.0267e+01, -1.4080e+01, -1.3307e+01,\n         -1.2843e+01, -1.0119e+01, -1.2837e+01, -1.0396e+01, -9.8503e+00],\n        [-2.1649e+01, -6.0199e-05, -2.0626e+01, -2.1195e+01, -9.7776e+00,\n         -1.9270e+01, -1.9040e+01, -1.3190e+01, -1.4067e+01, -1.4086e+01],\n        [-2.4818e+00, -5.8397e+00, -2.9723e-01, -2.4417e+00, -4.4367e+00,\n         -3.8704e+00, -5.7469e+00, -4.0153e+00, -3.6395e+00, -5.6767e+00],\n        [-1.2651e+01, -9.1769e+00, -6.5345e+00, -8.0312e-02, -1.4064e+01,\n         -6.6215e+00, -2.0803e+01, -2.7137e+00, -5.4480e+00, -5.6035e+00],\n        [-1.1973e+01, -1.0979e+01, -1.1710e+01, -1.4722e+01, -3.7592e-04,\n         -1.1858e+01, -1.1000e+01, -1.1559e+01, -1.1298e+01, -8.1176e+00],\n        [-1.6542e+01, -1.5770e+01, -1.5592e+01, -1.0364e+01, -2.0431e+01,\n         -6.2702e-05, -1.3264e+01, -1.5405e+01, -1.0474e+01, -1.4442e+01],\n        [-1.4763e+01, -2.1999e+01, -2.1197e+01, -1.8974e+01, -1.6232e+01,\n         -1.3618e+01, -2.5034e-06, -2.7055e+01, -1.3970e+01, -2.1741e+01],\n        [-2.2933e+01, -1.5030e+01, -1.6355e+01, -1.5551e+01, -1.8811e+01,\n         -1.8022e+01, -3.4099e+01, -1.6451e-05, -1.8116e+01, -1.1051e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.3460e+01, -1.1029e+01, -1.3291e+01, -9.3616e+00, -1.6707e+01,\n         -8.3963e+00, -1.3317e+01, -1.4513e+01, -3.7663e-04, -1.0045e+01],\n        [-2.0266e-06, -2.7242e+01, -1.4258e+01, -1.9590e+01, -1.8492e+01,\n         -1.6792e+01, -1.4198e+01, -1.6595e+01, -1.6352e+01, -1.4480e+01],\n        [-2.4378e+01, -4.7684e-07, -1.8723e+01, -2.3072e+01, -1.6808e+01,\n         -2.0166e+01, -2.0196e+01, -1.6307e+01, -1.4717e+01, -2.0838e+01],\n        [-1.3251e+01, -1.1117e+01, -6.7950e-03, -5.9788e+00, -1.7326e+01,\n         -9.8284e+00, -1.7380e+01, -6.0936e+00, -6.2616e+00, -1.2358e+01],\n        [-2.1282e+01, -1.3822e+01, -1.4232e+01, -1.9131e-04, -2.2064e+01,\n         -8.9921e+00, -3.1472e+01, -1.1960e+01, -1.0572e+01, -1.0315e+01],\n        [-1.7294e+01, -1.3283e+01, -1.6653e+01, -2.0033e+01, -6.5565e-06,\n         -1.6815e+01, -1.4660e+01, -1.3326e+01, -1.5370e+01, -1.2921e+01],\n        [-1.3843e+01, -1.0027e+01, -1.0287e+01, -1.0148e+01, -1.0309e+01,\n         -1.1004e+01, -2.0863e+01, -3.5099e-03, -1.0852e+01, -5.7090e+00],\n        [-1.6052e+01, -1.4127e+01, -1.2947e+01, -1.4415e+01, -1.6584e+01,\n         -1.5429e+01, -1.6362e+01, -1.8187e+01, -1.9550e-05, -1.1095e+01],\n        [-1.1545e+01, -1.0558e+01, -1.0685e+01, -1.0338e+01, -2.6048e+00,\n         -8.4211e+00, -1.4239e+01, -6.6522e+00, -9.0663e+00, -7.8646e-02],\n        [-1.7914e+01, -1.1295e+01, -1.6304e+01, -1.5097e+01, -1.4670e+01,\n         -1.5830e+01, -2.7729e+01, -1.3649e-04, -1.7403e+01, -9.0023e+00]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.4092e+01, -1.2492e+01, -1.1590e+01, -1.2682e+01, -1.8046e+01,\n         -1.3772e+01, -1.5079e+01, -1.7357e+01, -3.7550e-05, -1.0850e+01],\n        [-1.2116e+01, -1.5236e+01, -1.5511e+01, -1.4649e+01, -1.0324e+01,\n         -9.3883e+00, -1.7927e-04, -1.9089e+01, -9.7998e+00, -1.3846e+01],\n        [-1.2789e+01, -6.6567e+00, -1.4387e+01, -1.2169e+01, -2.0288e-01,\n         -6.8508e+00, -1.2362e+01, -4.2679e+00, -7.5286e+00, -1.7914e+00],\n        [-2.4962e+01, -5.9605e-07, -2.1360e+01, -2.4162e+01, -1.4640e+01,\n         -2.0181e+01, -1.9214e+01, -1.7374e+01, -1.6233e+01, -2.0254e+01],\n        [-1.2513e+01, -1.2384e+01, -1.1643e+01, -1.0832e+01, -5.1651e+00,\n         -9.2671e+00, -1.8323e+01, -2.9102e+00, -9.1375e+00, -6.2317e-02],\n        [-1.0624e+01, -7.9189e+00, -5.9262e+00, -6.4636e-02, -1.2692e+01,\n         -3.3906e+00, -1.6041e+01, -4.5970e+00, -4.3582e+00, -5.8230e+00],\n        [-9.5855e+00, -3.6402e+00, -7.9625e+00, -8.0375e+00, -5.3863e+00,\n         -7.8964e+00, -7.5251e+00, -7.5790e+00, -3.5441e-02, -6.3030e+00],\n        [-1.5544e+01, -1.3654e+01, -1.4317e+01, -1.7670e+01, -1.0609e-04,\n         -1.3548e+01, -1.1352e+01, -1.2125e+01, -1.1625e+01, -9.4761e+00],\n        [-2.0030e+01, -1.5463e+01, -1.8469e+01, -2.2701e+01, -2.5868e-05,\n         -1.7758e+01, -1.7273e+01, -1.5743e+01, -1.7075e+01, -1.0576e+01],\n        [-1.5799e+01, -1.0302e+01, -1.1013e+01, -1.0369e+01, -1.3517e+01,\n         -1.3532e+01, -2.5722e+01, -5.6418e-04, -1.2186e+01, -7.6529e+00]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-4.2915e-06, -2.6855e+01, -1.3294e+01, -1.8300e+01, -2.1962e+01,\n         -1.6045e+01, -1.3082e+01, -1.9385e+01, -1.4938e+01, -1.6240e+01],\n        [-1.9838e+01, -2.0146e-05, -1.6324e+01, -1.7302e+01, -1.2722e+01,\n         -1.6094e+01, -1.7536e+01, -1.1209e+01, -1.2660e+01, -1.5870e+01],\n        [-7.7350e+00, -1.1465e+01, -9.1421e+00, -7.7410e+00, -4.6898e+00,\n         -8.9993e+00, -1.2187e+01, -7.3798e+00, -7.6771e+00, -1.1459e-02],\n        [-1.7284e+01, -1.1843e+01, -1.6604e-04, -9.3849e+00, -1.2918e+01,\n         -1.3168e+01, -1.7610e+01, -9.6133e+00, -1.2567e+01, -1.8647e+01],\n        [-1.2723e+01, -1.1967e+01, -1.1029e+01, -9.5402e+00, -1.7312e+01,\n         -1.3281e+01, -1.5670e+01, -1.5956e+01, -1.6819e-04, -9.5829e+00],\n        [-1.4959e+01, -9.4851e+00, -1.2015e+01, -1.1391e+01, -1.3872e+01,\n         -1.4112e+01, -2.5503e+01, -3.8879e-04, -1.4006e+01, -8.1368e+00],\n        [-1.5078e+01, -1.5105e+01, -1.3568e+01, -7.6225e+00, -2.1181e+01,\n         -8.8159e+00, -1.6935e+01, -1.6551e+01, -7.1786e-04, -9.4594e+00],\n        [-1.4653e+01, -1.0997e+01, -3.0292e-03, -6.1513e+00, -1.1900e+01,\n         -1.1610e+01, -1.7510e+01, -7.0833e+00, -1.0724e+01, -1.6569e+01],\n        [-1.1935e+01, -1.9113e+01, -1.7023e+01, -1.6052e+01, -1.4291e+01,\n         -1.2311e+01, -1.3471e-05, -2.3617e+01, -1.3300e+01, -2.0066e+01],\n        [-5.8412e-06, -2.5561e+01, -1.3928e+01, -1.8682e+01, -1.7996e+01,\n         -1.6816e+01, -1.2670e+01, -1.7339e+01, -1.4447e+01, -1.3443e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-5.7387e+00, -1.1109e+01, -8.9685e+00, -1.2001e+01, -1.2066e+00,\n         -1.0235e+01, -3.6067e-01, -1.1835e+01, -1.1382e+01, -8.8040e+00],\n        [-8.4141e+00, -7.8487e+00, -1.1368e+01, -5.8062e+00, -1.1025e+01,\n         -1.7188e-01, -1.9673e+00, -1.1688e+01, -4.2576e+00, -8.1750e+00],\n        [-2.9697e+01, -1.8896e+01, -1.8770e+01, -2.0266e-06, -3.1177e+01,\n         -1.3349e+01, -4.1718e+01, -1.9172e+01, -1.4820e+01, -1.6734e+01],\n        [-1.7150e+01, -1.2291e+01, -1.1182e+01, -3.7696e-03, -1.9948e+01,\n         -6.0075e+00, -2.2946e+01, -1.2147e+01, -6.7003e+00, -9.9503e+00],\n        [-9.6088e+00, -1.0008e+01, -6.7040e+00, -1.5693e+00, -1.5944e+01,\n         -1.0286e+00, -1.1385e+01, -7.3801e+00, -8.4197e-01, -6.5240e+00],\n        [-1.3805e+01, -8.3990e+00, -1.5073e+01, -1.0332e+01, -1.6237e+00,\n         -1.0224e+01, -1.8361e+01, -6.4525e+00, -1.0998e+01, -2.2197e-01],\n        [-1.5476e+01, -2.9011e-04, -1.2799e+01, -1.3594e+01, -1.0902e+01,\n         -1.1577e+01, -1.2448e+01, -9.4724e+00, -8.6492e+00, -1.3200e+01],\n        [-1.2352e+01, -1.4907e+01, -1.2495e+01, -1.6876e+01, -2.2292e-05,\n         -1.4769e+01, -1.2936e+01, -1.2949e+01, -1.6401e+01, -1.1660e+01],\n        [-3.9815e-05, -2.1703e+01, -1.1549e+01, -1.6330e+01, -1.8398e+01,\n         -1.3351e+01, -1.1371e+01, -1.4479e+01, -1.1264e+01, -1.2540e+01],\n        [-1.0043e+01, -1.6555e+01, -1.4842e+01, -1.5494e+01, -1.0176e+01,\n         -1.3004e+01, -8.8449e-05, -1.9842e+01, -1.2471e+01, -1.5564e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.9028e+01, -9.6559e-06, -1.6259e+01, -1.8676e+01, -1.2877e+01,\n         -1.5818e+01, -1.5020e+01, -1.3379e+01, -1.2233e+01, -1.6353e+01],\n        [-1.0610e-05, -2.4133e+01, -1.2337e+01, -1.7680e+01, -1.8305e+01,\n         -1.4707e+01, -1.3163e+01, -1.4424e+01, -1.3427e+01, -1.3155e+01],\n        [ 0.0000e+00, -3.3213e+01, -1.7491e+01, -2.4121e+01, -2.5019e+01,\n         -2.1203e+01, -1.6818e+01, -2.4037e+01, -1.8851e+01, -1.9300e+01],\n        [-4.5374e+00, -1.0118e+01, -7.4704e+00, -9.6657e+00, -3.2217e+00,\n         -8.9142e+00, -5.3116e-02, -1.1119e+01, -8.9802e+00, -8.5543e+00],\n        [-1.1201e+01, -1.1499e+01, -2.8470e-01, -2.0340e+00, -1.0960e+01,\n         -7.7708e+00, -1.8113e+01, -2.2121e+00, -5.0520e+00, -7.3793e+00],\n        [-1.7365e+01, -4.0530e-05, -1.2962e+01, -1.9434e+01, -1.3715e+01,\n         -1.5584e+01, -1.3215e+01, -1.3834e+01, -1.0285e+01, -1.7341e+01],\n        [-2.2619e+01, -1.1921e-06, -1.8100e+01, -2.1314e+01, -1.4642e+01,\n         -1.8463e+01, -1.8686e+01, -1.4753e+01, -1.4793e+01, -1.8977e+01],\n        [-1.6363e+01, -1.1542e+01, -1.1470e+01, -1.0423e+01, -1.4618e+01,\n         -1.3405e+01, -2.5954e+01, -4.6922e-04, -1.2967e+01, -7.7875e+00],\n        [-1.6495e+01, -5.7729e+00, -1.1336e+01, -8.0671e+00, -1.4108e+01,\n         -1.3553e+01, -2.7745e+01, -4.0244e-03, -1.2244e+01, -7.4647e+00],\n        [-7.7225e+00, -6.8333e+00, -5.3789e+00, -4.3437e+00, -1.0301e+01,\n         -7.4736e+00, -9.7084e+00, -8.1444e+00, -2.2815e-02, -5.9982e+00]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-2.0660e+01, -1.4323e+01, -1.8129e+01, -2.2556e+01, -4.2915e-06,\n         -1.8828e+01, -2.0476e+01, -1.3939e+01, -2.0277e+01, -1.2759e+01],\n        [-1.6032e+01, -1.9538e+01, -2.0029e+01, -1.9621e+01, -1.3281e+01,\n         -1.3592e+01, -5.4836e-06, -2.5414e+01, -1.2925e+01, -2.0646e+01],\n        [-9.3337e-05, -2.0633e+01, -1.0379e+01, -1.4245e+01, -1.4989e+01,\n         -1.2170e+01, -1.0401e+01, -1.3716e+01, -1.1299e+01, -1.1305e+01],\n        [-1.7289e+01, -1.2909e+01, -1.0998e+01, -8.9725e+00, -1.6298e+01,\n         -1.2505e+01, -2.8555e+01, -4.5313e-04, -1.3952e+01, -8.1044e+00],\n        [-1.2398e-05, -2.3831e+01, -1.2428e+01, -1.7347e+01, -1.9266e+01,\n         -1.5783e+01, -1.2174e+01, -1.7568e+01, -1.2911e+01, -1.4370e+01],\n        [-2.4333e+01, -1.6641e+01, -1.5658e+01, -3.5524e-05, -2.7000e+01,\n         -1.0879e+01, -3.2123e+01, -1.8964e+01, -1.1050e+01, -1.4284e+01],\n        [-1.2459e+01, -1.8931e+01, -1.8100e+01, -1.8898e+01, -1.0209e+01,\n         -1.4764e+01, -4.1603e-05, -2.3273e+01, -1.4585e+01, -1.7315e+01],\n        [-1.0703e+01, -1.3033e+01, -1.1570e+01, -6.4912e+00, -1.5818e+01,\n         -9.4107e+00, -1.4804e+01, -1.4069e+01, -3.1846e-03, -6.4722e+00],\n        [-2.2664e+01, -8.4203e+00, -1.4774e+01, -1.3068e+01, -1.6828e+01,\n         -1.8277e+01, -3.3884e+01, -2.2802e-04, -1.8169e+01, -1.2198e+01],\n        [-2.0523e+01, -7.8678e-06, -1.7768e+01, -1.9430e+01, -1.2369e+01,\n         -1.6989e+01, -1.6997e+01, -1.3253e+01, -1.3340e+01, -1.6127e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-2.0561e+01, -1.2277e+01, -1.9099e+01, -7.6181e+00, -2.1403e+01,\n         -4.9936e-04, -1.3839e+01, -2.1348e+01, -1.3079e+01, -1.6664e+01],\n        [-5.2163e+00, -1.0076e+01, -7.4178e-02, -4.6457e+00, -8.5073e+00,\n         -6.5567e+00, -9.9574e+00, -5.5753e+00, -3.1826e+00, -4.6582e+00],\n        [-2.1454e+01, -1.4398e+01, -1.9212e+01, -2.3854e+01, -2.8610e-06,\n         -1.8970e+01, -2.1767e+01, -1.5461e+01, -2.0736e+01, -1.3098e+01],\n        [-1.6714e+01, -1.5313e+01, -1.5569e+01, -1.1477e+01, -6.4174e+00,\n         -8.9746e+00, -2.0241e+01, -7.3096e+00, -9.3412e+00, -2.5304e-03],\n        [-1.9962e+01, -1.4976e+01, -1.7408e+01, -2.3003e+01, -4.1723e-06,\n         -1.8020e+01, -1.8018e+01, -1.6220e+01, -1.8473e+01, -1.2505e+01],\n        [-1.0904e+01, -8.1356e+00, -2.9944e+00, -1.1583e-01, -1.3306e+01,\n         -5.5112e+00, -1.4924e+01, -4.6868e+00, -3.0886e+00, -8.6825e+00],\n        [-4.0486e+00, -7.5969e+00, -5.8080e+00, -7.2104e+00, -6.1630e-01,\n         -6.2421e+00, -8.9891e-01, -7.3955e+00, -3.7742e+00, -5.1430e+00],\n        [-1.5295e+01, -1.1246e+01, -1.5999e+01, -1.6489e+01, -9.5644e-04,\n         -1.2506e+01, -1.4837e+01, -1.0753e+01, -1.4006e+01, -6.9952e+00],\n        [-2.8348e+01,  0.0000e+00, -2.4051e+01, -2.4749e+01, -1.6645e+01,\n         -2.2960e+01, -2.5401e+01, -1.6764e+01, -1.8922e+01, -2.0536e+01],\n        [-1.8091e+01, -1.3794e+01, -1.5558e+01, -1.5615e+01, -1.4355e+01,\n         -1.6191e+01, -2.8101e+01, -1.9370e-04, -1.6811e+01, -8.5605e+00]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.2426e+01, -1.2138e+01, -1.9759e+00, -1.7852e-01, -1.4474e+01,\n         -7.3699e+00, -2.0540e+01, -4.0778e+00, -4.9385e+00, -9.1005e+00],\n        [-6.8732e+00, -1.2290e+01, -8.6041e+00, -1.0255e+01, -7.9242e+00,\n         -8.6823e+00, -1.8498e-03, -1.4883e+01, -9.7675e+00, -1.4183e+01],\n        [-1.1367e+01, -1.2598e+01, -1.4432e+01, -1.2574e+01, -1.3080e+01,\n         -8.4160e+00, -2.9560e-04, -1.9701e+01, -9.8407e+00, -1.8341e+01],\n        [ 0.0000e+00, -4.2296e+01, -2.2588e+01, -3.1376e+01, -3.4408e+01,\n         -2.6355e+01, -2.1679e+01, -2.8151e+01, -2.3651e+01, -2.3868e+01],\n        [-1.9667e+01, -2.2173e-05, -1.6883e+01, -1.8598e+01, -1.2206e+01,\n         -1.7930e+01, -1.9251e+01, -1.1032e+01, -1.4087e+01, -1.5423e+01],\n        [-1.3220e+01, -2.9772e+00, -6.0525e-02, -7.4870e+00, -1.7066e+01,\n         -1.0581e+01, -1.5284e+01, -5.6394e+00, -5.6125e+00, -1.5240e+01],\n        [-1.7655e+01, -1.2396e+01, -1.0108e+01, -2.2410e-02, -2.2306e+01,\n         -9.3615e+00, -2.4530e+01, -1.2589e+01, -3.8162e+00, -1.1068e+01],\n        [-2.3340e+01, -1.5968e+01, -1.8919e+01, -2.3856e+01, -1.0729e-06,\n         -1.8606e+01, -2.0750e+01, -1.5759e+01, -1.8861e+01, -1.4057e+01],\n        [-3.0419e+01, -2.5198e+01, -2.8612e+01, -1.5832e+01, -2.8720e+01,\n         -1.1921e-07, -2.4875e+01, -2.5865e+01, -2.0402e+01, -1.9644e+01],\n        [-1.6110e+01, -2.3084e+01, -2.1736e+01, -1.9987e+01, -1.7208e+01,\n         -1.5695e+01, -1.1921e-06, -2.8784e+01, -1.3967e+01, -2.3225e+01]],\n       grad_fn=<LogSoftmaxBackward>)\ntensor([[-1.9759e+01, -8.3706e+00, -1.3187e+01, -1.2357e+01, -1.7118e+01,\n         -1.9561e+01, -3.3953e+01, -2.4340e-04, -1.6002e+01, -1.2118e+01],\n        [-1.1779e+01, -1.3641e+01, -1.0711e+01, -1.0112e+01, -2.3145e+01,\n         -1.3695e+01, -1.6236e+01, -1.8332e+01, -7.9152e-05, -1.1983e+01],\n        [-1.4766e+01, -1.2607e+01, -1.4501e+01, -1.3768e+01, -5.5176e-01,\n         -1.0025e+01, -1.6373e+01, -9.9655e+00, -1.2265e+01, -8.5810e-01],\n        [-2.8034e-04, -1.8592e+01, -9.7790e+00, -1.3821e+01, -1.5780e+01,\n         -1.2894e+01, -9.7877e+00, -1.4474e+01, -8.8829e+00, -1.0605e+01],\n        [-1.8038e+01, -4.6729e-05, -1.4300e+01, -1.7204e+01, -1.0666e+01,\n         -1.4675e+01, -1.2656e+01, -1.1922e+01, -1.1304e+01, -1.6275e+01],\n        [-1.8940e+01, -7.4654e+00, -6.6163e-04, -1.0142e+01, -2.0643e+01,\n         -1.5058e+01, -2.0091e+01, -1.0314e+01, -1.1038e+01, -2.2313e+01],\n        [-2.1457e+01, -1.3595e+01, -1.4672e+01, -9.5298e-04, -2.3268e+01,\n         -6.9955e+00, -2.9474e+01, -1.4872e+01, -1.1729e+01, -1.0541e+01],\n        [-2.0323e+01, -1.1973e+01, -1.9307e+01, -2.0482e+01, -1.1956e-04,\n         -1.5939e+01, -1.8192e+01, -1.2001e+01, -1.4112e+01, -9.1503e+00],\n        [-2.5478e+01, -2.3329e+01, -2.6740e+01, -1.5867e+01, -3.0577e+01,\n         -2.3842e-07, -1.9087e+01, -2.4178e+01, -1.5691e+01, -2.0473e+01],\n        [-2.2266e+01, -3.2170e+01, -3.1342e+01, -2.9002e+01, -2.3085e+01,\n         -2.1270e+01,  0.0000e+00, -3.9340e+01, -2.0265e+01, -3.1250e+01]],\n       grad_fn=<LogSoftmaxBackward>)\nAccuracy:  0.963\n"
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "# with torch.no_grad():\n",
    "for data in testset:\n",
    "    X, y = data\n",
    "    output = net(X.view(-1,784))\n",
    "    print(output)\n",
    "    for idx, i in enumerate(output):\n",
    "        #print(torch.argmax(i), y[idx])\n",
    "        if torch.argmax(i) == y[idx]:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Created with matplotlib (https://matplotlib.org/) -->\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n <defs>\n  <style type=\"text/css\">\n*{stroke-linecap:butt;stroke-linejoin:round;}\n  </style>\n </defs>\n <g id=\"figure_1\">\n  <g id=\"patch_1\">\n   <path d=\"M 0 248.518125 \nL 251.565 248.518125 \nL 251.565 0 \nL 0 0 \nz\n\" style=\"fill:none;\"/>\n  </g>\n  <g id=\"axes_1\">\n   <g id=\"patch_2\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \nL 244.365 7.2 \nL 26.925 7.2 \nz\n\" style=\"fill:#ffffff;\"/>\n   </g>\n   <g clip-path=\"url(#p499cce18cb)\">\n    <image height=\"218\" id=\"image5c0c747c4b\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAABHNCSVQICAgIfAhkiAAABYVJREFUeJzt3U+I1GUcx/GZXdt01TVr3SWiIo3KP0lIhHSKVIiCiNg6RBcPZgRR0h9Bu7XVKSI6Kh06tFJUYlBkEEGgEhlsQYpSUlCWmnqwtZTd7dQp51mdcT4zs/t6Xb/7m+eH+N4H5uH32+ra6tBkBWiqrlbfAMwEQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBMxq9Q10quqdK4rzZ3e8X3O2Zs5Y8dpdfy0szrc/8kBxPjF6oDgnz44GAUKDAKFBgNAgQGgQIDQI8PV+nU6umF+cT/UVfsmDc08V568vXVCczx+te2maxI4GAUKDAKFBgNAgQGgQIDQIEBoEOEfrQMs3fV+c/7IjdCNcNDsaBAgNAoQGAUKDAKFBgNAgQGgQUF1bHZps9U10oq7e3uJ89d7TNWdb+svnYFMZmzxXnN/3wqbivG9kX0Prc+nsaBAgNAgQGgQIDQKEBgFCgwChQYDn0eo0MVZ+b+PYRE/T1u6tlj/72F3l6/tGLuPNcFHsaBAgNAgQGgQIDQKEBgFCgwChQYBztCbZve3umrPhrfubuvb6NV8W519VZjd1ff7PjgYBQoMAoUGA0CBAaBAgNAjw9X6TXDtyoOZseOPK4rUv9X93uW+HFrOjQYDQIEBoECA0CBAaBAgNAoQGAf5sUwsce6r2IzSVSqXy9da3Gvr8E+Nni/M1216sObv+5T0Nrc2F2dEgQGgQIDQIEBoECA0ChAYBQoMA52gt0N1/TXF+++d/FufDA429rq50zvbw5ueL1/aN7Gto7ZnKjgYBQoMAoUGA0CBAaBAgNAgQGgR4r2MLjJ8on5Pt3l5+Xm14S2PnaP3dc2rOjq+qFq/tG2lo6RnLjgYBQoMAoUGA0CBAaBAgNAjwmEwb6h4cKM6Xf3q8OH918Ju6157qVXUeo6mPHQ0ChAYBQoMAoUGA0CBAaBAgNAjwmEwbGv/jWHG+6/DK4ryRc7TSIzSVSqWy5OmDxflxj9FckB0NAoQGAUKDAKFBgNAgQGgQIDQIcI7WgW58s/xKuCOr/y7Ob5o1u+61Hx/YW5y/UVla92dPZ3Y0CBAaBAgNAoQGAUKDAKFBgNAgwDlaB6ruGS3ONx56rDjfvezDutde0VP+k1NnHl1dnM97b2a+99GOBgFCgwChQYDQIEBoECA0CBAaBDhHm4ZOfXxd+QeW1f/Zg1O89/H0kvLv7nn1L93R7GgQIDQIEBoECA0ChAYBQoOAjv56v/uqBTVn1asXFq/9YfOi4nz20SuK88Xv/FacN9PE7+U/67To27HQnXCx7GgQIDQIEBoECA0ChAYBQoMAoUFAR5+jVT6aW3O085YPmrv2huZ+fMn9Bx8qzk+OOUdrN3Y0CBAaBAgNAoQGAUKDAKFBgNAgoKPP0Z674bOas6PjZ4vXDnZfWZx3tfHvoE9u29nqW6hp4N5fyz/wWuY+2k37/m+CaURoECA0CBAaBAgNAoQGAUKDgOra6tBkq2+iXuP3rKo56xk9Urz25yeXFufn5zf2zzI89G7N2bo5R4vXdlWrxXlvtaeue0rY+093cf7K4jtCd9Je7GgQIDQIEBoECA0ChAYBQoMAoUFAR5+jTVfdt95cnB/a0F+cTyw6V5z/tO7tS76n//x4/kxx/sT6Z4rzWV/sr3vtTmZHgwChQYDQIEBoECA0CBAaBPh6HwLsaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoOAfwEh4aTULr9vtwAAAABJRU5ErkJggg==\" y=\"-6.64\"/>\n   </g>\n   <g id=\"matplotlib.axis_1\">\n    <g id=\"xtick_1\">\n     <g id=\"line2d_1\">\n      <defs>\n       <path d=\"M 0 0 \nL 0 3.5 \n\" id=\"m9a01fcbb38\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#m9a01fcbb38\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_1\">\n      <!-- 0 -->\n      <defs>\n       <path d=\"M 31.78125 66.40625 \nQ 24.171875 66.40625 20.328125 58.90625 \nQ 16.5 51.421875 16.5 36.375 \nQ 16.5 21.390625 20.328125 13.890625 \nQ 24.171875 6.390625 31.78125 6.390625 \nQ 39.453125 6.390625 43.28125 13.890625 \nQ 47.125 21.390625 47.125 36.375 \nQ 47.125 51.421875 43.28125 58.90625 \nQ 39.453125 66.40625 31.78125 66.40625 \nz\nM 31.78125 74.21875 \nQ 44.046875 74.21875 50.515625 64.515625 \nQ 56.984375 54.828125 56.984375 36.375 \nQ 56.984375 17.96875 50.515625 8.265625 \nQ 44.046875 -1.421875 31.78125 -1.421875 \nQ 19.53125 -1.421875 13.0625 8.265625 \nQ 6.59375 17.96875 6.59375 36.375 \nQ 6.59375 54.828125 13.0625 64.515625 \nQ 19.53125 74.21875 31.78125 74.21875 \nz\n\" id=\"DejaVuSans-48\"/>\n      </defs>\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_2\">\n     <g id=\"line2d_2\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#m9a01fcbb38\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_2\">\n      <!-- 5 -->\n      <defs>\n       <path d=\"M 10.796875 72.90625 \nL 49.515625 72.90625 \nL 49.515625 64.59375 \nL 19.828125 64.59375 \nL 19.828125 46.734375 \nQ 21.96875 47.46875 24.109375 47.828125 \nQ 26.265625 48.1875 28.421875 48.1875 \nQ 40.625 48.1875 47.75 41.5 \nQ 54.890625 34.8125 54.890625 23.390625 \nQ 54.890625 11.625 47.5625 5.09375 \nQ 40.234375 -1.421875 26.90625 -1.421875 \nQ 22.3125 -1.421875 17.546875 -0.640625 \nQ 12.796875 0.140625 7.71875 1.703125 \nL 7.71875 11.625 \nQ 12.109375 9.234375 16.796875 8.0625 \nQ 21.484375 6.890625 26.703125 6.890625 \nQ 35.15625 6.890625 40.078125 11.328125 \nQ 45.015625 15.765625 45.015625 23.390625 \nQ 45.015625 31 40.078125 35.4375 \nQ 35.15625 39.890625 26.703125 39.890625 \nQ 22.75 39.890625 18.8125 39.015625 \nQ 14.890625 38.140625 10.796875 36.28125 \nz\n\" id=\"DejaVuSans-53\"/>\n      </defs>\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_3\">\n     <g id=\"line2d_3\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#m9a01fcbb38\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_3\">\n      <!-- 10 -->\n      <defs>\n       <path d=\"M 12.40625 8.296875 \nL 28.515625 8.296875 \nL 28.515625 63.921875 \nL 10.984375 60.40625 \nL 10.984375 69.390625 \nL 28.421875 72.90625 \nL 38.28125 72.90625 \nL 38.28125 8.296875 \nL 54.390625 8.296875 \nL 54.390625 0 \nL 12.40625 0 \nz\n\" id=\"DejaVuSans-49\"/>\n      </defs>\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_4\">\n     <g id=\"line2d_4\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#m9a01fcbb38\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_4\">\n      <!-- 15 -->\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_5\">\n     <g id=\"line2d_5\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#m9a01fcbb38\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_5\">\n      <!-- 20 -->\n      <defs>\n       <path d=\"M 19.1875 8.296875 \nL 53.609375 8.296875 \nL 53.609375 0 \nL 7.328125 0 \nL 7.328125 8.296875 \nQ 12.9375 14.109375 22.625 23.890625 \nQ 32.328125 33.6875 34.8125 36.53125 \nQ 39.546875 41.84375 41.421875 45.53125 \nQ 43.3125 49.21875 43.3125 52.78125 \nQ 43.3125 58.59375 39.234375 62.25 \nQ 35.15625 65.921875 28.609375 65.921875 \nQ 23.96875 65.921875 18.8125 64.3125 \nQ 13.671875 62.703125 7.8125 59.421875 \nL 7.8125 69.390625 \nQ 13.765625 71.78125 18.9375 73 \nQ 24.125 74.21875 28.421875 74.21875 \nQ 39.75 74.21875 46.484375 68.546875 \nQ 53.21875 62.890625 53.21875 53.421875 \nQ 53.21875 48.921875 51.53125 44.890625 \nQ 49.859375 40.875 45.40625 35.40625 \nQ 44.1875 33.984375 37.640625 27.21875 \nQ 31.109375 20.453125 19.1875 8.296875 \nz\n\" id=\"DejaVuSans-50\"/>\n      </defs>\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"xtick_6\">\n     <g id=\"line2d_6\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#m9a01fcbb38\" y=\"224.64\"/>\n      </g>\n     </g>\n     <g id=\"text_6\">\n      <!-- 25 -->\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"matplotlib.axis_2\">\n    <g id=\"ytick_1\">\n     <g id=\"line2d_7\">\n      <defs>\n       <path d=\"M 0 0 \nL -3.5 0 \n\" id=\"m57cbf50c5e\" style=\"stroke:#000000;stroke-width:0.8;\"/>\n      </defs>\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m57cbf50c5e\" y=\"11.082857\"/>\n      </g>\n     </g>\n     <g id=\"text_7\">\n      <!-- 0 -->\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_2\">\n     <g id=\"line2d_8\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m57cbf50c5e\" y=\"49.911429\"/>\n      </g>\n     </g>\n     <g id=\"text_8\">\n      <!-- 5 -->\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_3\">\n     <g id=\"line2d_9\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m57cbf50c5e\" y=\"88.74\"/>\n      </g>\n     </g>\n     <g id=\"text_9\">\n      <!-- 10 -->\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_4\">\n     <g id=\"line2d_10\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m57cbf50c5e\" y=\"127.568571\"/>\n      </g>\n     </g>\n     <g id=\"text_10\">\n      <!-- 15 -->\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-49\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_5\">\n     <g id=\"line2d_11\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m57cbf50c5e\" y=\"166.397143\"/>\n      </g>\n     </g>\n     <g id=\"text_11\">\n      <!-- 20 -->\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\n      </g>\n     </g>\n    </g>\n    <g id=\"ytick_6\">\n     <g id=\"line2d_12\">\n      <g>\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m57cbf50c5e\" y=\"205.225714\"/>\n      </g>\n     </g>\n     <g id=\"text_12\">\n      <!-- 25 -->\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\n       <use xlink:href=\"#DejaVuSans-50\"/>\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\n      </g>\n     </g>\n    </g>\n   </g>\n   <g id=\"patch_3\">\n    <path d=\"M 26.925 224.64 \nL 26.925 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_4\">\n    <path d=\"M 244.365 224.64 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_5\">\n    <path d=\"M 26.925 224.64 \nL 244.365 224.64 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n   <g id=\"patch_6\">\n    <path d=\"M 26.925 7.2 \nL 244.365 7.2 \n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\n   </g>\n  </g>\n </g>\n <defs>\n  <clipPath id=\"p499cce18cb\">\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\n  </clipPath>\n </defs>\n</svg>\n",
      "text/plain": "<Figure size 432x288 with 1 Axes>"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(X[0].view(28,28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "tensor(7)\n"
    }
   ],
   "source": [
    "print(torch.argmax(net(X[0].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}